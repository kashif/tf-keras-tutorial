{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IZrAitlFLdEZ"
   },
   "source": [
    "# Fashion-MNIST with tf.keras\n",
    "\n",
    "Welcome! In this lab, you'll learn how to train an image classifier train on the [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist) using TensorFlow 2. You'll go through all the steps, including loading the data, building and training a model, calculating the accuracy, and making predictions. Our focus here is on the code.\n",
    "\n",
    "The biggest change to TensorFlow is that it runs with eager execution by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jSmUsjJfMEqC"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-preview'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B8Lhscw0NDln"
   },
   "source": [
    "### Step 1: Download the dataset\n",
    "\n",
    "The Fashion-MNIST dataset contains thousands of grayscale images of Zalando fashion articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "FKiwTuT-NE6f"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eEFU58MaNPpk"
   },
   "source": [
    "### Step 2) Visualize the data\n",
    "Let's see how the images look. This function shows a random example along with it's corresponding label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "AwxNOsCMNNGd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fab2545ad68>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "i = random.randint(0, 100)\n",
    "\n",
    "print(\"Label: %s\" % train_labels[i])\n",
    "plt.imshow(train_images[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each training and test example is assigned one of the following labels:\n",
    "\n",
    "| Label | Description |\n",
    "| --- | --- |\n",
    "| 0 | T-shirt/top |\n",
    "| 1 | Trouser |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e2n2NVdKNk5i"
   },
   "source": [
    "### Step 3) Understand the data format\n",
    "\n",
    "We are given the images as a 3-D array of integer values that is of shape (*N*, 28, 28), where *N* is the number of images in the training or test set. The labels are 1-D array of the integer values of each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TTj2ZWMBN24i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eo_cZXaqODnZ"
   },
   "source": [
    "### Step 4) Reformat the images\n",
    "Here, we'll flatten (or unstack) the images. There are deep learning techniques that work with 2d images directly (rather than their flattened representation), but we'll start with this format. Instead of working with a 28 by 28 *image*, we'll unstack it into a 28 \\* 28 = 784 length *array*.\n",
    "\n",
    "* We want to convert the 3-D array of shape (*N*, 28, 28) to a 2-D array of shape (*N*, 784) where the second dimension is just an array of all the pixels in an image. This is called flattening, or unstacking, the images. \n",
    "* We also want to convert the pixel values from a number between 0 and 255 to a number between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "OgnV5FJjP5Vz"
   },
   "outputs": [],
   "source": [
    "TRAINING_SIZE = len(train_images)\n",
    "TEST_SIZE = len(test_images)\n",
    "\n",
    "# Reshape from (N, 28, 28) to (N, 28*28=784)\n",
    "train_images = np.reshape(train_images, (TRAINING_SIZE, 784))\n",
    "test_images = np.reshape(test_images, (TEST_SIZE, 784))\n",
    "\n",
    "# Convert the array to float32 as opposed to uint8\n",
    "train_images = train_images.astype(np.float32)\n",
    "test_images = test_images.astype(np.float32)\n",
    "\n",
    "# Convert the pixel values from integers between 0 and 255 to floats between 0 and 1\n",
    "train_images /= 255\n",
    "test_images /=  255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GI25z0StQH-P"
   },
   "source": [
    "### Step 5) Reformat the labels\n",
    "\n",
    "Next, we want to convert the labels from an integer format (e.g., \"2\" or \"Pullover\"), to a [one hot encoding](https://en.wikipedia.org/wiki/One-hot) (e.g., \"0, 0, 1, 0, 0, 0, 0, 0, 0, 0\"). To do so, we'll use the `tf.keras.utils.to_categorical` [function](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "E9yrkEENQ9Vz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before 9\n",
      "After [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "NUM_CAT = 10\n",
    "\n",
    "print(\"Before\", train_labels[0]) # The format of the labels before conversion\n",
    "\n",
    "train_labels  = tf.keras.utils.to_categorical(train_labels, NUM_CAT)\n",
    "\n",
    "print(\"After\", train_labels[0]) # The format of the labels after conversion\n",
    "\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, NUM_CAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pjdbemHURkpv"
   },
   "source": [
    "### Step 6) Build the model\n",
    "\n",
    "Now, we'll create our neural network using the [Keras Sequential API](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential). Keras is a high-level API to build and train deep learning models and is user friendly, modular and easy to extend. `tf.keras` is TensorFlow's implementation of this API and it supports such things as eager execution, `tf.data` pipelines and Estimators.\n",
    "\n",
    "Architecture wise, we'll use a single hidden layer network, where:\n",
    "* The hidden layer will have 512 units using the [ReLU](https://www.tensorflow.org/api_docs/python/tf/keras/activations/relu) activation function. \n",
    "* The output layer will have 10 units and use [softmax](https://www.tensorflow.org/api_docs/python/tf/keras/activations/softmax) function. \n",
    "* Notice, we specify the input shape on the first layer. If you add subsequent layers, this is not necessary (shame on you PyTorch üòú). \n",
    "* We will use the [categorical crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/categorical_crossentropy) loss function, and the [RMSProp](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/RMSprop) optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mNscbvHkUrMc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(784,)))\n",
    "model.add(tf.keras.layers.Dense(NUM_CAT, activation=tf.nn.softmax))\n",
    "\n",
    "# We will now compile and print out a summary of our model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k3br9Yi6VuBT"
   },
   "source": [
    "### Step 7) Training\n",
    "\n",
    "Next, we will train the model by using the [fit method](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#fit) for 5 [epochs](https://www.quora.com/What-is-epochs-in-machine-learning). We will keep track of the training loss and accuracy as we go. Please be patient as this step may take a while depending on your hardware (or laugh at those who do not have a giant NVidia GPU on their laptop üçè)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gBs0LwqcVXx6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000==============================] - 5s 75us/sample - loss: 0.4949 - acc: 0.8230\n",
      "Epoch 2/5\n",
      "60000/60000==============================] - 4s 69us/sample - loss: 0.3785 - acc: 0.8664\n",
      "Epoch 3/5\n",
      "60000/60000==============================] - 4s 68us/sample - loss: 0.3547 - acc: 0.8759\n",
      "Epoch 4/5\n",
      "60000/60000==============================] - 4s 69us/sample - loss: 0.3424 - acc: 0.8841\n",
      "Epoch 5/5\n",
      "60000/60000==============================] - 4s 68us/sample - loss: 0.3352 - acc: 0.8880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fab27af79b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rcYMPkwkWIPq"
   },
   "source": [
    "### Step 8) Testing\n",
    "Now that we have trained our model, we want to evaluate it. Sure, our model is >88% accurate on the training set, but what about on data it hasn't seen before? The test accuracy is a good metric for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "iuqDe4NiWBpU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000==============================] - 0s 44us/sample - loss: 0.4367 - acc: 0.8591\n",
      "Test accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy: %.2f' % (accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jo-yoMwvXkw6"
   },
   "source": [
    "## Congratulations\n",
    "You have successfully used TensorFlow Keras to train a model on the Fashion-MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "1-mnist-with-keras.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
